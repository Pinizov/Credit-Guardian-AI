"""Import remaining Bulgarian codes not yet in database."""
import time, re, requests, sqlite3
from datetime import datetime
from bs4 import BeautifulSoup

REMAINING_CODES = [
    ("–ù–ê–ö–ê–ó–ê–¢–ï–õ–ù–û-–ü–†–û–¶–ï–°–£–ê–õ–ï–ù –ö–û–î–ï–ö–°","https://www.ciela.net/svobodna-zona-normativi/view/2135512224/nakazatelno-protsesualen-kodeks"),
    ("–ì–†–ê–ñ–î–ê–ù–°–ö–ò –ü–†–û–¶–ï–°–£–ê–õ–ï–ù –ö–û–î–ï–ö–°","https://www.ciela.net/svobodna-zona-normativi/view/2135558368/grazhdanski-protsesualen-kodeks"),
    ("–ï–¢–ò–ß–ï–ù –ö–û–î–ï–ö–° –ù–ê –ê–î–í–û–ö–ê–¢–ê","https://www.ciela.net/svobodna-zona-normativi/view/2135507578/etichen-kodeks-na-advokata"),
    ("–°–ï–ú–ï–ï–ù –ö–û–î–ï–ö–°","https://www.ciela.net/svobodna-zona-normativi/view/2135637484/semeen-kodeks"),
    ("–ö–û–î–ï–ö–° –ó–ê –ü–†–û–§–ï–°–ò–û–ù–ê–õ–ù–ê –ï–¢–ò–ö–ê –ù–ê –ú–ê–ì–ò–°–¢–™–†-–§–ê–†–ú–ê–¶–ï–í–¢–ê","https://www.ciela.net/svobodna-zona-normativi/view/2135896487/kodeks-za-profesionalna-etika-na-magistar-farmatsevta"),
    ("–ö–û–î–ï–ö–° –ó–ê –ü–†–û–§–ï–°–ò–û–ù–ê–õ–ù–ê –ï–¢–ò–ö–ê –ù–ê –õ–ï–ö–ê–†–ò–¢–ï –ü–û –î–ï–ù–¢–ê–õ–ù–ê –ú–ï–î–ò–¶–ò–ù–ê (–ó–ê–ì–õ. –ò–ó–ú. - –î–í, –ë–†. 18 –û–¢ 2017 –ì.)","https://www.ciela.net/svobodna-zona-normativi/view/2135896489/kodeks-za-profesionalna-etika-na-lekarite-po-dentalna-meditsina-(zagl-izm---dv-br-18-ot-2017-g)"),
    ("–ò–ó–ë–û–†–ï–ù –ö–û–î–ï–ö–° –û–¢ 2011 –ì.","https://www.ciela.net/svobodna-zona-normativi/view/2135715515/izboren-kodeks-ot-2011-g"),
    ("–ö–û–î–ï–ö–° –ù–ê –ú–ï–ñ–î–£–ù–ê–†–û–î–ù–û–¢–û –ß–ê–°–¢–ù–û –ü–†–ê–í–û","https://www.ciela.net/svobodna-zona-normativi/view/2135503651/kodeks-na-mezhdunarodnoto-chastno-pravo"),
]

UA = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0 Safari/537.36'}

def fetch(url):
    try:
        r = requests.get(url, headers=UA, timeout=35)
        r.encoding='utf-8'
        if r.status_code!=200:
            print(f"  ‚ùå HTTP {r.status_code}")
            return None
        soup = BeautifulSoup(r.content,'html.parser')
        c = soup.find('div',class_='law-content') or soup.find('div',class_='document-content') or soup.find('div',id='content') or soup.find('article') or soup.find('main') or soup.find('body')
        if not c:
            return None
        text = c.get_text(separator='\n', strip=True)
        text = re.sub(r'\n\s*\n','\n\n',text)
        text = re.sub(r' +',' ',text)
        arts = []
        pattern = r'(?:–ß–ª\.|–ß–ª–µ–Ω)\s*(\d+[–∞-—è]?)\.'
        ms = list(re.finditer(pattern,text))
        for i,m in enumerate(ms):
            start=m.start(); end= ms[i+1].start() if i+1 < len(ms) else min(start+5000,len(text))
            seg=text[start:end].strip()
            if len(seg)>50:
                arts.append((m.group(1), seg))
        return text[:50000], arts
    except Exception as e:
        print(f"  ‚ùå Error {e}")
        return None

def main():
    conn = sqlite3.connect('credit_guardian.db')
    cur = conn.cursor()
    imported=0
    for title,url in REMAINING_CODES:
        cur.execute("SELECT id FROM legal_documents WHERE title=? LIMIT 1",(title,))
        if cur.fetchone():
            print(f"‚úÖ Skip existing: {title[:40]}")
            continue
        print(f"\nüìò {title}")
        data = fetch(url)
        if not data:
            print("  ‚ö†Ô∏è Skip no content")
            continue
        full_text, articles = data
        now = datetime.utcnow()
        cur.execute("INSERT INTO legal_documents (title, document_type, document_number, promulgation_date, effective_date, full_text, source_url, is_active, created_at, updated_at) VALUES (?,?,?,?,?,?,?,?,?,?)",
                    (title,'code',None,None,None,full_text,url,1,now,now))
        doc_id = cur.lastrowid
        added=0
        for num, text in articles[:150]:
            cur.execute("INSERT INTO legal_articles (document_id, article_number, title, content, chapter, section, created_at, updated_at) VALUES (?,?,?,?,?,?,?,?)",
                        (doc_id,num,f"–ß–ª–µ–Ω {num}",text,None,None,now,now))
            added+=1
        conn.commit()
        imported+=1
        print(f"  ‚úÖ Imported ID {doc_id} articles {added}")
        time.sleep(1.5)
    cur.execute("SELECT COUNT(*) FROM legal_documents WHERE document_type='code'")
    print("\nCode documents total:", cur.fetchone()[0])
    cur.execute("SELECT COUNT(*) FROM legal_articles")
    print("Total articles:", cur.fetchone()[0])
    conn.close()
    print(f"\n‚úÖ Remaining codes imported: {imported}")

if __name__=='__main__':
    main()
