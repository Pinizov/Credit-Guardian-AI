version: "3.9"

# Docker Compose for CPU-only systems (no GPU)
# Usage: docker-compose -f docker-compose.cpu.yml up -d

services:
  # =============================================================================
  # OLLAMA - Local LLM Server (CPU Mode)
  # =============================================================================
  ollama:
    image: ollama/ollama:latest
    container_name: cg_ollama
    restart: unless-stopped
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    # No GPU configuration - runs on CPU

  # Pull the model after Ollama starts
  ollama-pull:
    image: ollama/ollama:latest
    container_name: cg_ollama_pull
    depends_on:
      - ollama
    restart: "no"
    environment:
      - OLLAMA_HOST=http://ollama:11434
    entrypoint: ["/bin/sh", "-c"]
    command:
      - |
        sleep 15
        ollama pull llama3.2
        echo "âœ… Model llama3.2 ready!"

  # =============================================================================
  # DATABASE - PostgreSQL
  # =============================================================================
  db:
    image: postgres:15-alpine
    container_name: cg_postgres
    restart: unless-stopped
    environment:
      POSTGRES_DB: credit_guardian
      POSTGRES_USER: cg_user
      POSTGRES_PASSWORD: cg_pass
    ports:
      - "5432:5432"
    volumes:
      - pgdata:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U cg_user -d credit_guardian"]
      interval: 10s
      timeout: 5s
      retries: 5

  # =============================================================================
  # BACKEND API - FastAPI
  # =============================================================================
  api:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cg_api
    restart: unless-stopped
    depends_on:
      db:
        condition: service_healthy
      ollama:
        condition: service_started
    environment:
      DATABASE_URL: postgresql+psycopg2://cg_user:cg_pass@db:5432/credit_guardian
      AI_PROVIDER: ollama
      OLLAMA_URL: http://ollama:11434
      OLLAMA_MODEL: llama3.2
      LOG_LEVEL: INFO
    ports:
      - "8080:8000"
    volumes:
      - ./uploads:/app/uploads
    command: ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "8000"]
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # =============================================================================
  # DATABASE MIGRATIONS
  # =============================================================================
  migrate:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: cg_migrate
    depends_on:
      db:
        condition: service_healthy
    environment:
      DATABASE_URL: postgresql+psycopg2://cg_user:cg_pass@db:5432/credit_guardian
    entrypoint: ["sh", "-c", "alembic upgrade head"]
    restart: "no"

  # =============================================================================
  # FRONTEND - React + Vite + Nginx
  # =============================================================================
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
      args:
        VITE_API_URL: http://localhost:8080
    container_name: cg_frontend
    restart: unless-stopped
    depends_on:
      - api
    ports:
      - "3000:80"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3

volumes:
  pgdata:
  ollama_data:

